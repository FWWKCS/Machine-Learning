{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO61rMF8y4J9jt65NvR/O4n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FWWKCS/Machine-Learning/blob/main/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5%EA%B0%9C%EB%A1%A0/04%EC%A3%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 도미/빙어의 평균, 분산, 최소, 최대값"
      ],
      "metadata": {
        "id": "dX886tktuQEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,\n",
        "                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,\n",
        "                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8,\n",
        "                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]\n",
        "fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,\n",
        "                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,\n",
        "                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7,\n",
        "                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]\n",
        "\n",
        "# 데이터 구분(슬라이싱)\n",
        "bream_length = fish_length[:35]\n",
        "smelt_length = fish_length[35:]\n",
        "\n",
        "bream_weight = fish_weight[:35]\n",
        "smelt_weight = fish_weight[35:]"
      ],
      "metadata": {
        "id": "0RvndUvyugbk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "q7nIk2KuxSZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bream_info = ['bream length','bream weight']\n",
        "smelt_info = ['smelt length','smelt weight']\n",
        "\n",
        "# 데이터 병합\n",
        "bream_data = np.column_stack((bream_length, bream_weight))\n",
        "smelt_data = np.column_stack((smelt_length, smelt_weight))\n",
        "\n",
        "# 데이터프레임 생성\n",
        "bream_df = pd.DataFrame(data = bream_data, columns = bream_info)\n",
        "smelt_df = pd.DataFrame(data = smelt_data, columns = smelt_info)\n",
        "\n",
        "\n",
        "\n",
        "# 평균과 분산 출력\n",
        "col_sta_data = ['mean','var']\n",
        "\n",
        "print('도미/빙어 데이터의 평균/분산')\n",
        "# 도미 평균/분산 데이터 결합\n",
        "bream_sta = np.column_stack((bream_df.mean().values, bream_df.var().values))\n",
        "\n",
        "# 빙어 평균/분산 데이터 결합\n",
        "smelt_sta = np.column_stack((smelt_df.mean().values, smelt_df.var().values))\n",
        "\n",
        "# 두 데이터 결합\n",
        "fish_sta = np.concatenate((bream_sta, smelt_sta))\n",
        "\n",
        "# 최종 데이터프레임 생성\n",
        "fish_sta_df = pd.DataFrame(data = fish_sta, index = bream_info + smelt_info, columns = col_sta_data)\n",
        "print(fish_sta_df)\n",
        "\n",
        "\n",
        "\n",
        "# 최소값, 최댓값 출력\n",
        "col_ext_data = ['min','max']\n",
        "\n",
        "print('\\n도미/빙어 데이터의 최소/최댓값')\n",
        "# 도미 데이터 최소/최댓값 결합\n",
        "bream_ext = np.column_stack((bream_df.min().values, bream_df.max().values))\n",
        "\n",
        "# 빙어 데이터 최소/최댓값 결합\n",
        "smelt_ext = np.column_stack((smelt_df.min().values, smelt_df.max().values))\n",
        "\n",
        "# 두 데이터 결합\n",
        "fish_ext = np.concatenate((bream_ext, smelt_ext))\n",
        "\n",
        "# 최종 데이터프레임 생성\n",
        "fish_ext_df = pd.DataFrame(data = fish_ext, index = bream_info + smelt_info, columns = col_ext_data)\n",
        "print(fish_ext_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUWD0ukyvqPo",
        "outputId": "48cfa376-2f41-4896-a0a7-55feeb5116de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "도미/빙어 데이터의 평균/분산\n",
            "                    mean           var\n",
            "bream length   33.108571     15.303160\n",
            "bream weight  617.828571  43767.028571\n",
            "smelt length   11.921429      2.051044\n",
            "smelt weight   11.178571     17.069505\n",
            "\n",
            "도미/빙어 데이터의 최소/최댓값\n",
            "                min     max\n",
            "bream length   25.4    41.0\n",
            "bream weight  242.0  1000.0\n",
            "smelt length    9.8    15.0\n",
            "smelt weight    6.7    19.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. MinMaxScaler를 이용해서  도미, 빙어데이터를 KNeighborsClassifier()로 분류\n",
        "# predict(), score()"
      ],
      "metadata": {
        "id": "hWE0CjnSuS-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler를 이용하여 데이터를 0~1의 값으로 정규화하고 그 데이터를 학습시킴\n",
        "\n",
        "fish_data = np.column_stack((fish_length, fish_weight))\n",
        "fish_target = np.concatenate((np.ones(35), np.zeros(14)))\n",
        "fish_info = ['length', 'weight']\n",
        "\n",
        "# 데이터프레임 생성\n",
        "fish_df = pd.DataFrame(data = fish_data, columns = fish_info)\n",
        "\n",
        "# 기존 fish_data 정규화 (스케일링)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# 스케일러 객체에 데이터프레임 적용\n",
        "scaler.fit(fish_df)\n",
        "# 기존 데이터를 스케일링한 객체의 데이터를 호출, 이때 nparray로 반환\n",
        "fish_scaled = scaler.transform(fish_df)\n",
        "# 스케일된 nparray를 데이터프레임으로 변환\n",
        "fish_scaled_df = pd.DataFrame(fish_scaled)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split # 데이터 분리 (훈련셋, 테스트셋)\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(fish_scaled_df, fish_target, stratify=fish_target, random_state=42)\n",
        "# stratify : 주어진 데이터의 요소의 개수 비에 맞춰 랜덤으로 섞기\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier # 최근접이웃 알고리즘으로 모델 학습\n",
        "\n",
        "kn = KNeighborsClassifier()\n",
        "kn.fit(train_input, train_target)\n",
        "# 데이터 테스트\n",
        "print('정규화 데이터를 학습한 최근접이웃 모델 테스트')\n",
        "print(kn.score(test_input, test_target))\n",
        "\n",
        "extra_data = [25, 150]\n",
        "# 모호한 데이터 예측\n",
        "print(f'\\n길이 {extra_data[0]}cm, 무게 {extra_data[1]}g 의 생선 예측')\n",
        "print(kn.predict([extra_data]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3dSzOU3H_py",
        "outputId": "5649b03c-1146-438e-af7c-c1df27589632"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정규화 데이터를 학습한 최근접이웃 모델 테스트\n",
            "1.0\n",
            "\n",
            "길이 25cm, 무게 150g 의 생선 예측\n",
            "[1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. cross_val_score() 도미 빙어 데이터 추가"
      ],
      "metadata": {
        "id": "t0s6DnC0ub0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_val_score메소드를 이용해 훈련셋의 각 n등분을 검증 데이터로 모델 학습\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 최근접이웃 모델\n",
        "kn = KNeighborsClassifier()\n",
        "\n",
        "# 교차검증 메소드\n",
        "# 파라미터 : (모델, 훈련 데이터의 정보, 훈련 데이터 타겟, 폴드 수)\n",
        "scores = cross_val_score(kn, fish_df, fish_target, cv=3)\n",
        "\n",
        "# 스케일링된 데이터를 파라미터로 지정할 경우\n",
        "# 기존 데이터보다 높은 정확도를 가지게 됨\n",
        "enhanced_scores = cross_val_score(kn, fish_scaled_df, fish_target, cv=3)\n",
        "\n",
        "# 훈련 데이터에 대한 성능을 출력\n",
        "print('# 기존 데이터를 교차검증')\n",
        "print('교차 검증별 정확도: ', np.round(scores, 4))\n",
        "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))\n",
        "\n",
        "print('\\n# 정규화된 데이터를 교차검증')\n",
        "print('교차 검증별 정확도: ', np.round(enhanced_scores, 4))\n",
        "print('평균 검증 정확도: ', np.round(np.mean(enhanced_scores), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtEBmZXd9EYZ",
        "outputId": "c61d54a8-ce8e-4d34-c80f-9bd7fe75eaa7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 기존 데이터를 교차검증\n",
            "교차 검증별 정확도:  [0.8824 1.     1.    ]\n",
            "평균 검증 정확도:  0.9608\n",
            "\n",
            "# 정규화된 데이터를 교차검증\n",
            "교차 검증별 정확도:  [1. 1. 1.]\n",
            "평균 검증 정확도:  1.0\n"
          ]
        }
      ]
    }
  ]
}